{"pubDate": "2025-05-25T11:00:00", "original_title": "A Quick Introduction to TCP Congestion Control", "link": "https://hackaday.com/2025/05/25/a-quick-introduction-to-tcp-congestion-control/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/05/congestion_management.png", "youtube": "https://www.youtube.com/watch?v=yiH1wLyeS5g", "original_content": "\nIt\u2019s hard to imagine now, but in the mid-1980s, the Internet came close to collapsing due to the number of users congesting its networks. Computers would request packets as quickly as they could, and when a router failed to process a packet in time, the transmitting computer would immediately request it again. This tended to result in an unintentional denial-of-service, and was degrading performance significantly. [Navek]s recent video goes over TCP congestion control, the solution to this problem which allows our much larger modern internet to work.In a 1987 paper, Van Jacobson described a method to restrain congestion: in a TCP connection, each side of the exchange estimates how much data it can have in transit (sent, but not yet acknowledged) at any given time. The sender and receiver exchange their estimates, and use the smaller estimate as the congestion window. Every time a packet is successfully delivered across the connection, the size of the window doubles.\nOnce packets start dropping, the sender and receiver divide the size of the window, then slowly and linearly ramp up the size of the window until it again starts dropping packets. This is called additive increase/multiplicative decrease, and the overall result is that the size of the window hovers somewhere around the limit. Any time congestion starts to occur, the computers back off. One way to visualize this is to look at a graph of download speed: the process of periodically hitting and cutting back from the congestion limit tends to create a sawtooth wave.[Navek] notes that this algorithm has rather harsh behavior, and that there are new algorithms that both recover faster from hitting the congestion limit and take longer to reach it. The overall concept, though, remains in widespread use. If you\u2019re interested in reading more, we\u2019ve previously covered network congestion control in more detail. We\u2019ve also covered [Navek]\u2019s previous video on IPV5.\n\nThanks to [Mahdi Naghavi] for the tip!"}