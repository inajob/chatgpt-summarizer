{"pubDate": "2025-06-19T18:30:44", "original_title": "Dual RGB Cameras Get Depth Sensing Powerup", "link": "https://hackaday.com/2025/06/19/dual-rgb-cameras-get-depth-sensing-powerup/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/06/Foundation-Stereo-Featured.png", "original_content": "Its sometimes useful for a system to not just have a flat 2D camera view of things, but to have an understanding of the depth of a scene. Dual RGB cameras can be used to sense depth by contrasting the two slightly different views, in much the same way that our own eyes work. Its considered an economical but limited method of depth sensing, or at least it was before FoundationStereo came along and blew previous results out of the water. That link has a load of interactive comparisons to play with and see for yourself, so check it out.\nA box of disordered tools at close range is understood very well, and these results are typical for the system.\nThe FoundationStereo paper explains how researchers leveraged machine learning to create a system that can not only outperform existing dual RGB camera setups, but even active depth-sensing cameras such as the Intel RealSense.\nFoundationStereo is specifically designed for strong zero-shot performance, meaning it delivers useful general results with no additional training needed to handle any particular scene or environment. The framework and models are available from the projects GitHub repository.\nMicrosoft may have discontinued the Kinect and Intel similarly discontinued RealSense, but depth sensing remains an enabling technology that opens possibilities and gives rise to interesting projects, like a headset that allows one to see the world through the eyes of a depth sensor.\nThe ability to easily and quickly gain an understanding of the physical layout of a space is a powerful tool, and if a system like this one can deliver such fantastic results with nothing more than two RGB cameras, thats a great sign. Watch it in action in the video below.\n\n", "title": "- \u30c7\u30e5\u30a2\u30ebRGB\u30ab\u30e1\u30e9\u306b\u3088\u308b\u6df1\u5ea6\u611f\u77e5\u306e\u65b0\u3057\u3044\u30a2\u30d7\u30ed\u30fc\u30c1", "body": "FoundationStereo\u306f\u3001\u4e8c\u3064\u306eRGB\u30ab\u30e1\u30e9\u3067\u6df1\u5ea6\u3092\u9ad8\u7cbe\u5ea6\u306b\u611f\u77e5\u3059\u308b\u6280\u8853\u3067\u3059\u3002", "titles": ["- \u30c7\u30e5\u30a2\u30ebRGB\u30ab\u30e1\u30e9\u306b\u3088\u308b\u6df1\u5ea6\u611f\u77e5\u306e\u65b0\u3057\u3044\u30a2\u30d7\u30ed\u30fc\u30c1", "- FoundationStereo: \u753b\u50cf\u51e6\u7406\u306e\u9769\u547d\u7684\u306a\u9032\u5316", "- \u6df1\u5ea6\u30bb\u30f3\u30b5\u30fc\u306e\u9650\u754c\u3092\u8d85\u3048\u308b\u6a5f\u68b0\u5b66\u7fd2\u306e\u529b", "- RGB\u30ab\u30e1\u30e9\u3067\u5f97\u3089\u308c\u308b\u7269\u7406\u7a7a\u9593\u306e\u7406\u89e3", "- \u8208\u5473\u6df1\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u5b9f\u73fe\u3059\u308b\u6df1\u5ea6\u30bb\u30f3\u30b5\u30fc\u6280\u8853"]}