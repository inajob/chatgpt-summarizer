{"pubDate": "2023-11-20T09:00:14", "original_title": "3D Human Models from a Single Image", "link": "https://hackaday.com/2023/11/20/3d-human-models-from-a-single-image/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2023/11/human3d.png", "original_content": "Youve seen it in movies and shows  the hero takes a blurry still picture, and with a few keystrokes, generates a view from a different angle or sometimes even a full 3D model. Turns out, thanks to machine learning and work by several researchers, this might be possible. As you can see in the video below, using shape-guided diffusion, the researchers were able to take a single image of a person and recreate a plausible 3D model.\nOf course, the work relies on machine learning. As youll see in the video, this isnt a new idea, but previous attempts have been less than stellar. This new method uses shape prediction first, followed by an estimate of the back view appearance. The algorithm then guesses what images go between the initial photograph and the back view. However, it uses the 3D shape estimate as a guideline. Even then,\u00a0 there is some post-processing to join the intermediate images together into a model.\nThe result looks good, although the video does point out some areas where they still fall short. For example, unusual lighting can affect the results.\nThis beats spinning around a person or a camera to get many images. Scanning people in 3D is a much older dream than you might expect.\n\n"}