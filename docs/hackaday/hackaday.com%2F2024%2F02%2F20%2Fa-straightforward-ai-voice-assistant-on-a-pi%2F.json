{"pubDate": "2024-02-20T12:00:07", "original_title": "A Straightforward AI Voice Assistant, On a Pi", "link": "https://hackaday.com/2024/02/20/a-straightforward-ai-voice-assistant-on-a-pi/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/02/local-llm-featured.jpg", "original_content": "With AI being all the rage at the moment its been somewhat annoying that using a large language model (LLM) without significant amounts of computing power meant surrendering to an online service run by a large company. But as happens with every technological innovation the state of the art has moved on, now to such an extent that a computer as small as a Raspberry Pi can join the fun. [Nick Bild] has one running on a Pi 4, and hes gone further than just a chatbot by making into a voice assistant.\nThe brains of the operation is a Tinyllama LLM, packaged as a llamafile, which is to say an executable that provides about as easy a one-step access to a local LLM as its currently possible to get. The whisper voice recognition sytem provides a text transcript of the input prompt, while the eSpeak speech synthesizer creates a voice output for the result. Theres a brief demo video weve placed below the break, which shows it working, albeit slowly.\nPerhaps the most important part of this project is that its easy to install and hes provided full instructions in a GitHub repository. We know that the quality and speed of these models on commodity single board computers will only increase with time, so wed rate this as an important step towards really good and cheap local LLMs. It may however be a while before it can help you make breakfast.\n\n"}