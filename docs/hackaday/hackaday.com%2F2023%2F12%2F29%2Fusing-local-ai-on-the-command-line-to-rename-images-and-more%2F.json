{"pubDate": "2023-12-29T16:00:00", "original_title": "Using Local AI on the Command Line To Rename Images (And More)", "link": "https://hackaday.com/2023/12/29/using-local-ai-on-the-command-line-to-rename-images-and-more/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2023/03/AIcoding.jpg", "original_content": "We all have a folder full of images whose filenames resemble line noise. How about renaming those images with the help of a local LLM (large language model) executable on the command line? All that and more is showcased on [Justine Tunney]s bash one-liners for LLMs, a showcase aimed at giving folks ideas and guidance on using a local (and private) LLM to do actual, useful work.\nThis is built out from the recent llamafile project, which turns LLMs into single-file executables. This not only makes them more portable and easier to distribute, but the executables are perfectly capable of being called from the command line and sending to standard output like any other UNIX tool. Its simpler to version control the embedded LLM weights (and therefore their behavior) when its all part of the same file as well.\nOne such tool (the multi-modal LLaVA) is capable of interpreting image content. As an example, we can point it to a local image of the Jolly Wrencher logo using the following command:\nllava-v1.5-7b-q4-main.llamafile --image logo.jpg --temp 0 -e -p '### User: The image has...\\n### Assistant:'\nWhich produces the following response:\nThe image has a black background with a white skull and crossbones symbol.\nWith a different prompt (What do you see? instead of The image has) the LLM even picks out the wrenches, but one can already see that the right pieces exist to do some useful work.\nCheck out [Justine]s rename-pictures.sh script, which cleverly evaluates image filenames. If an images given filename already looks like readable English (also a job for a local LLM) the image is left alone. Otherwise, the picture is fed to an LLM whose output guides the generation of a new short and descriptive English filename in lowercase, with underscores for spaces.\nWhat about the fact that LLM output isnt entirely predictable? Thats easy to deal with. [Justine] suggests always calling these tools with the --temp 0 parameter. Setting the temperature to zero makes the model deterministic, ensuring that a same input always yields the same output.\nTheres more neat examples on the Bash One-Liners for LLMs that demonstrate different ways to use a local LLM that lives in a single-file executable, so be sure to give it a look and see if you get any new ideas. After all, we have previously shown how automating tasks is almost always worth the time invested."}