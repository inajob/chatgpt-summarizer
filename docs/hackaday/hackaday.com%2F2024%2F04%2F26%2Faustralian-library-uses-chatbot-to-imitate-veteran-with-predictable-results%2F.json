{"pubDate": "2024-04-27T02:00:13", "original_title": "Australian Library Uses Chatbot To Imitate Veteran With Predictable Results", "link": "https://hackaday.com/2024/04/26/australian-library-uses-chatbot-to-imitate-veteran-with-predictable-results/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/04/Screenshot-2024-04-26-173112-e1714118530614.png", "original_content": "The educational sector is usually the first to decry large language models and AI, due to worries about cheating. The State Library of Queensland, however, has embraced the technology in controversial fashion. In the lead-up to Anzac Day, the primarily Australian war memorial holiday, the library released a chatbot intended to imitate a World War One veteran. It went as well as youd expect.\nThe highlighted line was apparently added to the chatbots instructions later on to help shut down tomfoolery.\nTwitter users immediately chimed in with dismay at the very concept. Others showed how easy it was to jailbreak the AI, convincing Charlie he was actually supposed to teach Python, imitate Frasier Crane, or explain laws like Elle from Legally Blonde. One person figured out how to get Charlie to spit out his initial instructions; these were patched later in the day to try and stop some of the shenanigans.\nFrom those instructions, its clear that this was supposed to be educational, rather than some sort of macabre experiment. However, Charlie didnt do a great job here, either. As with any Large Language Model, Charlie had no sense of objective truth. He routinely spat out incorrect facts regarding the war, and regularly contradicted himself.\nGenerally, any plan that includes the words impersonate a veteran is a foolhardy one at best. Throwing a machine-generated portrait and a largely uncontrolled AI into the mix didnt help things. Regardless, the State Library has left the Virtual Veterans experience up at the time of writing.\nThe problem with AI is that its not a magic box that gets things right all the time. It never has been. As long as organizations keep putting AI to use in ways like this, the same story will keep playing out.", "title": "AI\u3092\u6d3b\u7528\u3057\u305f\u7b2c\u4e00\u6b21\u4e16\u754c\u5927\u6226\u30d9\u30c6\u30e9\u30f3\u306e\u6a21\u5023AI\u3001\u6559\u80b2\u76ee\u7684\u3067\u5931\u6557", "body": "\u30af\u30a4\u30fc\u30f3\u30ba\u30e9\u30f3\u30c9\u5dde\u7acb\u56f3\u66f8\u9928\u304c\u7b2c\u4e00\u6b21\u4e16\u754c\u5927\u6226\u306e\u9000\u5f79\u8ecd\u4eba\u3092\u6a21\u5023\u3057\u305f\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u3092\u30ea\u30ea\u30fc\u30b9\u3002\u3057\u304b\u3057\u3001AI\u306e\u8aa4\u60c5\u5831\u3084\u77db\u76fe\u306b\u3088\u308a\u554f\u984c\u304c\u767a\u751f\u3002AI\u306e\u554f\u984c\u70b9\u3092\u6307\u6458\u3059\u308b\u58f0\u304c\u5e83\u307e\u308b\u3082\u3001\u56f3\u66f8\u9928\u306f\u4eee\u60f3\u9000\u5f79\u8ecd\u4eba\u4f53\u9a13\u3092\u63d0\u4f9b\u3057\u7d9a\u3051\u3066\u3044\u308b\u3002", "titles": ["AI\u3092\u6d3b\u7528\u3057\u305f\u7b2c\u4e00\u6b21\u4e16\u754c\u5927\u6226\u30d9\u30c6\u30e9\u30f3\u306e\u6a21\u5023AI\u3001\u6559\u80b2\u76ee\u7684\u3067\u5931\u6557", "\u8ad6\u4e89\u3092\u5dfb\u304d\u8d77\u3053\u3059\u5dde\u7acb\u56f3\u66f8\u9928\u306e\"Virtual Veterans\"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8", "AI\u304c\u4e0d\u6b63\u78ba\u306a\u60c5\u5831\u3092\u63d0\u4f9b\u3059\u308b\u5371\u967a\u6027\uff1a\u6226\u4e89\u306e\u4e8b\u5b9f\u3092\u8aa4\u308a\u3084\u77db\u76fe\u3067\u8fd4\u7b54", "Twitter\u30e6\u30fc\u30b6\u30fc\u304cAI\u3078\u306e\u610f\u898b\u8868\u660e\uff1a\u60b2\u89b3\u7684\u306a\u53cd\u5fdc\u3001\u30b7\u30b9\u30c6\u30e0\u30cf\u30c3\u30ad\u30f3\u30b0\u3001\u6559\u80b2\u76ee\u7684\u3078\u306e\u63d0\u6848", "AI\u306b\u3088\u308b\u6a21\u5023\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304b\u3089\u898b\u308bAI\u5229\u7528\u306e\u30ea\u30b9\u30af\uff1a\u7d44\u7e54\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3068\u7d50\u679c"]}