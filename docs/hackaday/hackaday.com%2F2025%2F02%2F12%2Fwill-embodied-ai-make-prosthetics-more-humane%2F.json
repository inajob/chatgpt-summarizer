{"pubDate": "2025-02-12T21:00:00", "original_title": "Will Embodied AI Make Prosthetics More Humane?", "link": "https://hackaday.com/2025/02/12/will-embodied-ai-make-prosthetics-more-humane/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2023/02/ChatGPT-1.jpg", "original_content": "Building a robotic arm and hand that matches human dexterity is tougher than it looks. We can create aesthetically pleasing ones, very functional ones, but the perfect mix of both? Still a work in progress. Just ask [Sarah de Lagarde], who in 2022 literally lost an arm and a leg in a life-changing accident. In this BBC interview, she shares her experiences openly  highlighting both the promise and the limits of today\u2019s prosthetics.\nThe problem is that our hands aren\u2019t just grabby bits. They\u2019re intricate systems of nerves, tendons, and ridiculously precise motor control. Even the best AI-powered prosthetics rely on crude muscle signals, while dexterous robots struggle with the simplest things  like tying shoelaces or flipping a pancake without launching it into orbit.\nThat doesn\u2019t mean progress isn\u2019t happening. Researchers are training robotic fingers with real-world data, moving from \u2018oops\u2019 to actual precision. Embodied AI, i.e. machines that learn by physically interacting with their environment, is bridging the gap. Soft robotics with AI-driven feedback loops mimic how our fingers instinctively adjust grip pressure. If haptics are your point of interest, we have posted about it before.\nThe future isn\u2019t just robots copying our movements, it\u2019s about them understanding touch. Instead of machine learning, we might want to shift focus to human learning. If AI cracks that, we\u2019re one step closer.\nOriginal photo by Marco Bianchetti on Unsplash\n"}