{"pubDate": "2025-02-26T12:00:25", "original_title": "New Camera Does Realtime Holographic Capture, No Coherent Light Required", "link": "https://hackaday.com/2025/02/26/new-camera-does-realtime-holographic-capture-no-coherent-light-required/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/02/Holographic-camera-liquid-lens.png", "original_content": "Holography is about capturing 3D data from a scene, and being able to reconstruct that scene  preferably in high fidelity. Holography is not a new idea, but engaging in it is not exactly a point-and-shoot affair. One needs coherent light for a start, and it generally only gets touchier from there. But now researchers describe a new kind of holographic camera that can capture a scene better and faster than ever. How much better? The camera goes from scene capture to reconstructed output in under 30 milliseconds, and does it using plain old incoherent light.\nThe camera and liquid lens is tiny. Together with the computation back end, they can make a holographic capture of a scene in under 30 milliseconds.\nThe new camera is a two-part affair: acquisition, and calculation. Acquisition consists of a camera with a custom electrically-driven liquid lens design that captures a focal stack of a scene within 15 ms. The back end is a deep learning neural network system (FS-Net) which accepts the camera data and computes a high-fidelity RGB hologram of the scene in about 13 ms.\u00a0 How good are the results? They beat other methods, and reconstruction of the scene using the data looks really, really good.\nOne might wonder what makes this different from, say, a 3D scene captured by a stereoscopic camera, or with an RGB depth camera (like the now-discontinued Intel RealSense). Those methods capture 2D imagery from a single perspective, combined with depth data to give an understanding of a scenes physical layout.\nHolography by contrast captures a scenes wavefront information, which is to say it captures not just where light is coming from, but how it bends and interferes. This information can be used to optically reconstruct a scene in a way data from other sources cannot; for example allowing one to shift perspective and focus.\nBeing able to capture holographic data in such a way significantly lowers the bar for development and experimentation in holography  something thats traditionally been tricky to pull off for the home gamer.", "title": "- \u9ad8\u901f\u30fb\u9ad8\u7cbe\u5ea6\u306a\u65b0\u578b\u30db\u30ed\u30b0\u30e9\u30d5\u30a3\u30ab\u30e1\u30e9\u306e\u767b\u5834", "body": "\u65b0\u3057\u3044\u30db\u30ed\u30b0\u30e9\u30d5\u30a3\u30ab\u30e1\u30e9\u306f\u300130ms\u4ee5\u5185\u3067\u9ad8\u7cbe\u5ea6\u306a3D\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u53ef\u80fd\u3067\u3059\u3002", "titles": ["- \u9ad8\u901f\u30fb\u9ad8\u7cbe\u5ea6\u306a\u65b0\u578b\u30db\u30ed\u30b0\u30e9\u30d5\u30a3\u30ab\u30e1\u30e9\u306e\u767b\u5834", "- 30\u30df\u30ea\u79d2\u3067\u30b7\u30fc\u30f3\u3092\u518d\u69cb\u6210\u3059\u308b\u9769\u65b0\u7684\u6280\u8853", "- \u96fb\u6c17\u99c6\u52d5\u306e\u6db2\u4f53\u30ec\u30f3\u30ba\u3092\u7528\u3044\u305f\u30db\u30ed\u30b0\u30e9\u30d5\u30a3\u30fc\u306e\u672a\u6765", "- \u6df1\u5c64\u5b66\u7fd2\u3067\u9ad8\u5fe0\u5b9f\u5ea6RGB\u30db\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u73fe", "- \u30db\u30ed\u30b0\u30e9\u30d5\u30a3\u30fc\u306e\u6577\u5c45\u3092\u4e0b\u3052\u308b\u65b0\u3057\u3044\u30a2\u30d7\u30ed\u30fc\u30c1"]}