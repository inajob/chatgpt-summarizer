{"pubDate": "2025-04-30T17:02:54", "original_title": "Supercon 2024: Photonics/Optical Stack for Smart-Glasses", "link": "https://hackaday.com/2025/04/30/supercon-2024-photonics-optical-stack-for-smart-glasses/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/04/kennedy_feat.png", "youtube": "https://www.youtube.com/watch?v=DssK3cYSPCw", "original_content": "Smart glasses are a complicated technology to work with. The smart part is usually straightforward enough\u2014microprocessors and software are perfectly well understood and easy to integrate into even very compact packages. Its the glasses part that often proves challenging\u2014figuring out the right optics to create a workable visual interface that sits mere millimeters from the eye.\nDev Kennedy is no stranger to this world. He came to the 2024 Hackaday Supercon to give a talk and educate us all on photonics, optical stacks, and the technology at play in the world of smart glasses.\n\nGood Optics\n\nDevs talk begins with an apology. He notes that its not possible to convey an entire photonics and optics syllabus in a short presentation, which is understandable enough. His warning, regardless, is that his talk is as dense as possible to maximise the insight into the technical information he has to offer.\nThings get heavy fast, as Dev dives into a breakdown of all the different basic technologies out there that can be used for building smart glasses. On one slide, he lays them all out with pros and cons across the board. There are a wide range of different illumination and projection technologies, everything from micro-OLED displays to fancy liquid crystal on silicon (LCOS) devices that are used to create an image with the aid of laser illumination. When youre building smart glasses, though, thats only half the story.\nDev explains the various optical technologies involved in AR and their strengths and weaknesses.\nOnce youve got something to make an image, you then need something to put it on in front of the eye. Dev goes on to talk about different techniques for doing this, from reflective waveguides to the amusingly-named birdbath combiners. Ultimately, youre hunting for something that provides a clear and visible image to the user in all conditions, while still providing a great view of the world around them, too. This can be particularly challenging in high-brightness conditions, like walking around outdoors in daylight.\nThe talk also focuses on a particular bugbear for Dev\u2014the fact that AR and VR arent treated as differently as they should be. VR is a stack of pancakes, says Dev. Why is it a stack of pancakes? Its because all of the PCBs, the optics, the emissions source for the light\u2014is in front of the users nose. Because VR is just about beaming images into the eye, with no regard for the outside world, its a little more straightforward. Its basically a stack of technology outward from the eye relief point to the back of the device. Dev explains.\nWhen it comes to AR, though, the solutions must be more complicated. Whats different is AR is actually an archer, says Dev, referring to the way such devices must fling light around. What an archer does is it shoots light around the side of the arm, and it might have to bend it one way or another, up on the crossbar and spread it out through a waveguide, and at the very exist point at the coupling out portion the light has to make one more right turn towards your eye. Ultimately, the optics and display hardware involved tend to diverge a long way from what can be used in VR displays. These technologies are fundamentally different, says Dev. It strains me to great extent that people kind of batch them into the same category.\nSnapchats fifth-generation Spectacles have some interesting optics, but theyre perhaps not quite market ready in Devs opinion.\nThe talk also steps away from raw hardware chat, and covers some of the devices on the market, and those that left it years ago. Dev makes casual mention of Google Glass, spawned all the way back in 2013, before also noting developments Microsoft made with Hololens over the year. As for the current state of play, Dev namechecks Project Orion from Meta, as well as the fifth-generation of Snapchat Spectacles.\nHe gives particular credit to Meta for their work on refining input modalities that work with the smart glasses interrface paradigm. Meanwhile, he notes Snapchat needs work on comfort, weight, and looks, given how bulky their current product is. Overall, with these products, there are problems to be overcome before they can really become mainstream tools for every day use. The important part is the relatability of these devices, Dev goes on to explain. We dont see that just yet, as a $25,000 device from Meta and something that is too thick to be socially acceptable from Snapchat.\nFundamentally, as Devs talk highlights, AR remains a technology still at a nascent stage of development. Its worth remembering\u2014it took decades to develop computers that could fit in our pockets (smartphones) or on our wrists (smartwatches). Expect smart glasses to actually go mainstream as soon as the technical and optical issues are worked out, and the software and interface solutions actually help people in day to day life."}