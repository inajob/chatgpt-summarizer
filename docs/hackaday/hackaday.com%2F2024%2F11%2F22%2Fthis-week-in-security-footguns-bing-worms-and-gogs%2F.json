{"pubDate": "2024-11-22T15:00:34", "original_title": "This Week in Security: Footguns, Bing Worms, and Gogs", "link": "https://hackaday.com/2024/11/22/this-week-in-security-footguns-bing-worms-and-gogs/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2016/01/darkarts.jpg", "original_content": "The world of security research is no stranger to the phenomenon of not-a-vulnerability. Thats where a security researcher finds something interesting, reports it to the project, and it turns out that its something other than a real security vulnerability. There are times that this just means a researcher got over-zealous on reporting, and didnt really understand what was found. There is at least one other case, the footgun.\nA footgun is a feature in a language, library, or tool that too easily leads to catastrophic mistake  shooting ones self in the foot. The main difference between a footgun and a vulnerability is that a footgun is intentional, and a vulnerability is not. That line is sometimes blurred, so an undocumented footgun could also be a vulnerability, and one possible solution is to properly document the quirk. But sometimes the footgun should really just be eliminated. And thats what the article linked above is about. [Alex Leahu] takes a look at a handful of examples, which are not only educational, but also a good exercise in thinking through how to improve them.\n\nThe first example is Tesla from the Elixer language. Tesla is an HTTP/HTTPS client, not unlike libcurl, and the basic usage pattern is to initialize an instance with a base_url defined. So we could create an instance, and set the URL base to https://hackaday.com. Then, to access a page or endpoint on that base URL, you just call a Tesla.get(), and supply the client instance and path. The whole thing might look like:\nclient = build_client(config, \"https://hackaday.com\", headers)\nresponse = Tesla.get(client, \"/floss\")\nAll is well, as this code snippet does exactly what you expect. The footgun comes when your path isnt just /floss. If that path starts with a scheme, like http:// or https://, the base URL is ignored, and path is used as the entire URL instead. Is that a vulnerability? Its clearly documented, so no, definitely not. Is this a footgun, that is probably responsible for vulnerabilities in other code? Yes, very likely. And heres the interesting question: What is the ideal resolution? How do you get rid of the footgun?\nThere are two related approaches that come to mind. The first would be to add a function to the librarys API, a Tesla.get_safe() that will never replace the base URL, and update the documentation and examples to use the safe version. The related solution is to then take the extra step of deprecating the unsafe version of the function.\nThe other example well look at is Psychopg, a PostSQL driver library for Python. The example of correctly using the driver is cur.execute(\"INSERT INTO numbers VALUES (%s, %s)\", (10, 20)), while the incorrect example is cur.execute(\"INSERT INTO numbers VALUES (%s, %s)\" % (10, 20)). The difference may not seem huge, but the first example is sending the values of 10 and 20 as arguments to the library. The second example is doing an printf-like Python string formatting with the % operator. That means it bypasses all the protections this library has to prevent SQL injection. And its trivially easy because the library uses % notation. The ideal solution here is pretty straightforward. Deprecate the % SQL notation, and use a different character that isnt overloaded with a particularly dangerous language functino.\nWormable Bing\n[pedbap] went looking for a Cross-Site Scripting (XSS) flaw on Microsofts services. The interesting thing here is that Bing is part of that crowd of Microsoft websites, that users automatically get logged in to with their Microsft accounts. An XSS flaw there could have interesting repercussions for the entire system. And since were talking about it, there was obviously something there.\nThe flaw in question was found on Bing maps, where a specific URL can load a map with custom features, though the use of json file specified in the URL. That json file can also include a Keyhole Markup Language file, a KML. These files have a lot of flexibility, like including raw HTML. There is some checking to prevent running arbitrary JavaScript, but that was defeated with a simple mixed case string: jAvAsCriPt:(confirm)(1337). Now the example does require a click to launch the JS, so its unclear if this is actually wormable in the 0-click sort of way. Regardless, its a fun find, and netted [pedbap] a bounty.\n\nRight There in Plain Text\n[Ian] from Shells.Systems was inside a Palo Alto Global Protect installation, a VPN server running on a Windows machine. And there was something unusual in the system logs. The log contained redacted passwords. This is an odd thing to come across, particularly for a VPN server like this, because the server shouldnt ever have the passwords after creation.\nSo, to prove the point, [Ian] wrote an extractor program, that grabs the plaintext passwords from system memory. As far as we can tell, this doesnt have a CVE or a fix, as its a program weakness rather than a vulnerability.\nYour Gogs Need to Go\nSpeaking of issues that havent been patched, if youre running gogs, its probably time to retire it. The latest release has a Remote Code Execution vulnerability, where an authenticated user can create a symlink to a real file on the gogs server, and edit the contents. This is a very quick route to arbitrary code execution.\nThe real problem here isnt this specific vulnerability, or that it hasnt been patched yet, or even that gogs hasnt seen a release since 2023. The real problem is that the project seems to have been almost completely abandoned. The last change was only 2 weeks ago, but looking through the change log, almost all of the recent changes appear to be automated changes. The vulnerability was reported back in August, the 90 day disclosure deadline came and went, and there was never a word from the project. Thats concerning. Its reminiscent of the sci-fi trope, when some system keeps running itself even after all the humans have left.\nBits and bytes\nThe NPM account takeover hack now has an Open Source checking tool. This is the issue of expired domains still listed on the developer email addresses on NPM packages. If an attacker can register the dangling domain, its possible to take over the package as well. The team at Laburity are on it, with the release of this tool.\nLutra Security researchers have an interesting trick up their sleeves, when it comes to encrypted emails. What if the same encrypted text encrypted to different readable messages for each different reader? With some clever use of both encryption and the multipart/alternative MIME type, that;s what Salamander/MIME pulls off.\nAnd finally, its time to dive in to DOMPurify bypasses again. Thats the JavaScript library for HTML sanitizing using the browsers own logic to guarantee there arent any inconsistent parsing issues. And [Mizu] has the lowdown on how to pull off an inconsistent parsing attack. The key here is mutations. When DOMPurify runs an HTML document through the browsers parsing engine, that HTML is often modified  hence the Purify in the title. Whats not obvious is that a change made during this first iteration through the document can have unexpected consequences for the next iteration through the document. Its a fun read, and only part one, so keep your eyes peeled for the rest of it!"}