{"pubDate": "2025-06-07T17:00:46", "original_title": "ChatGPT Patched a BIOS Binary, and it Worked", "link": "https://hackaday.com/2025/06/07/chatgpt-patched-a-bios-binary-and-it-worked/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2023/03/AIcoding.jpg", "original_content": "[devicemodder] wrote in to let us know they managed to install Linux Mint on their FRP-locked Panasonic Toughpad FZ-A2.\nAndroid devices such as the FZ-A2 can be locked with Factory Reset Protection (FRP). The FRP limits what you can do with a device, tying it to a user account. On the surface thats a good thing for consumers as it disincentivizes stealing. Unfortunately, when combined with SecureBoot, it also means you cant just install whatever software you want on your hardware. [devicemodder] managed to get Linux Mint running on their FZ-A2, which is a notable achievement by itself, but even more remarkable is how it was done.\nSo how did [devicemodder] get around this limitation? The first step was to dump the BIOS using a CH341A-based programmer. From there, the image was uploaded to ChatGPT along with a request to disable SecureBoot. The resulting file was flashed back onto the FZ-A2, and all available fingers were crossed.\nAnd it worked! ChatGPT modified the BIOS enough that the Linux Mint installer could be booted from a flash drive. There are a bunch of bugs and issues to work through but in principle we have just seen AI capable enough to successfully patch a binary dump of BIOS code, which, for the record, is kind of hard to do. Were not sure what all of this might portend.\nSo is uploading binaries to ChatGPT with requests for mods vibe coding? Or should we invent a new term for this type of hack?"}