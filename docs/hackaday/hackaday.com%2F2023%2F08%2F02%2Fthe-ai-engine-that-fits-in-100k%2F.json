{"pubDate": "2023-08-02T23:00:52", "original_title": "The AI Engine that Fits in 100K", "link": "https://hackaday.com/2023/08/02/the-ai-engine-that-fits-in-100k/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2023/08/ai.png", "original_content": "Running your own AI models is possible, but it requires a giant computer, right? Maybe not. Researchers at NVidia are showing off Perfusion, a text-to-image model they say is 100KB in size and takes four minutes to train. The model specializes in customizing a photo. For example, the paper shows a picture of a teddy bear and a prompt to dress it as a wizard. In all fairness, the small size and quick training are a little misleading, we think, because the results are still using the usual giant model. Whats small and fast is the customization of the existing model.\nCustomizing models is a common task since you often want to work with something the model doesnt contain. For example, you might want to alter a picture of your face or your pet, which probably isnt in the original model. You can create a special keyword and partially train the model for what you want using something called textual inversion. The problem the researchers identified is that creating textual inversions often causes the new training to leak to unintended areas.\nThey describe key locking, a technique to avoid overfitting when fine-tuning an existing model. For example, suppose you want to add a specific dog picture to the model. With typical techniques, a special keyword like dog* will indicate the custom dog image, but the keyword has no connection with generic dogs, mammals, or animals. This makes it difficult for the AI to work with the image. For example, the prompts a man sitting and a dog sitting require very different image generations. But if we train a specific dog as dog* theres no deeper understanding that dog* is a type of dog that the model already knows about. So what do you do with dog* sitting? Key locking makes that association.\n\nConceptually, this seems like a no-brainer, but the devil is in the details and the math, of course. We assume future tools will integrate this kind of functionality where you might say something like: learn myface*.png as me* {person, human} adjectives: [tall, bearded, stocky]. Or something like that.\nWe are oddly fascinated and sometimes perplexed with all the AI engines and how they are progressing. Working with existing images is something we think has a lot of benefits."}