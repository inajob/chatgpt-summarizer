{"pubDate": "2025-03-23T08:00:00", "original_title": "Musings on a Good Parallel Computer", "link": "https://hackaday.com/2025/03/23/musings-on-a-good-parallel-computer/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/03/CELL_BE_processor_PS3_board.jpg", "original_content": "Until the late 1990s, the concept of a 3D accelerator card was something generally associated with high-end workstations. Video games and kin would run happily on the CPU in ones desktop system, with later extensions like MMX, 3DNow!, SSE, etc. providing a significant performance boost for games that supported it. As 3D accelerator cards (colloquially called graphics processing unit, or GPU) became prevalent, they took over almost all SIMD vector tasks, but one thing which theyre not good at is being a general parallel computer. While working on a software project this really ticked [Raph Levien] off and inspired him to cover his grievances.\nAlthough the interaction between CPUs and GPUs has become tighter over the decades, with PCIe in particular being a big improvement over AGP  PCI, GPUs are still terrible at running arbitrary computing tasks and PCIe links are still glacial compared to communication within the GPU  CPU dies. With the introduction of asynchronous graphic APIs this divide became even more intense. The proposal thus is to invert this relationship.\nTheres precedent for this already, with Intels Larrabee and IBMs Cell processor merging CPU and GPU characteristics on a single die, though both struggled with developing for such a new kind of architecture. Sonys PlayStation 3 was forced to add a GPU due to these issues. There is also the DirectStorage API in DirectX which bypasses the CPU when loading assets from storage, effectively adding CPU features to GPUs.\nAs [Raph] notes, so-called AI accelerators also have these characteristics, with often multiple SIMD-capable, CPU-like cores. Maybe the future is Cell after all."}