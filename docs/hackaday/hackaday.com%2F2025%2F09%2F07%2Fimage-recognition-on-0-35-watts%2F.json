{"pubDate": "2025-09-07T14:00:40", "original_title": "Image Recognition on 0.35 Watts", "link": "https://hackaday.com/2025/09/07/image-recognition-on-0-35-watts/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/09/grove_image_recognition.png", "original_content": "\nMuch of the expense of developing AI models, and much of the recent backlash to said models, stems from the massive amount of power they tend to consume. If you\u2019re willing to sacrifice some ability and accuracy, however, you can get ever-more-decent results from minimal hardware \u2013 a tradeoff taken by the Grove Vision AI board, which runs image recognition in near-real time on only 0.35 Watts.\nThe heart of the board is a WiseEye processor, which combines two ARM Cortex M55 CPUs and an Ethos U55 NPU, which handles AI acceleration. The board connects to a camera module and a host device, such as another microcontroller or a more powerful computer. When the host device sends the signal, the Grove board takes a picture, runs image recognition on it, and sends the results back to the host computer. A library makes signaling over I2C convenient, but in this example [Jaryd] used a UART.\nTo let it run on such low-power hardware, the image recognition model needs some limits; it can run YOLO8, but it can only recognize one object, runs at a reduced resolution of 192192, and has to be quantized down to INT8. Within those limits, though, the performance is impressive: 20-30 fps, good accuracy, and as [Jaryd] points out, less power consumption than a single key on a typical RGB-backlit keyboard. If you want another model, there are quite a few available, though apparently of varying quality. If all else fails, you can always train your own.\n\nSuch edge AI projects as these are all about achieving better performance with limited resources; if your requirements aren\u2019t too demanding, you can run speech recognition on much more limited devices. Of course, there are also some people who try to make image recognition less effective.\n", "title": "\u4f4e\u6d88\u8cbb\u96fb\u529b\u3067\u52d5\u4f5c\u3059\u308bGrove Vision AI\u30dc\u30fc\u30c9\u306e\u7d39\u4ecb", "body": "\u4f4e\u6d88\u8cbb\u96fb\u529b\u306eGrove Vision AI\u30dc\u30fc\u30c9\u306f\u3001\u753b\u50cf\u8a8d\u8b58\u3092\u52b9\u7387\u826f\u304f\u5b9f\u884c\u3057\u3001\u9650\u3089\u308c\u305f\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3067\u9ad8\u6027\u80fd\u3092\u5b9f\u73fe\u3057\u307e\u3059\u3002", "titles": ["\u4f4e\u6d88\u8cbb\u96fb\u529b\u3067\u52d5\u4f5c\u3059\u308bGrove Vision AI\u30dc\u30fc\u30c9\u306e\u7d39\u4ecb", "WiseEye\u30d7\u30ed\u30bb\u30c3\u30b5\u3067\u5b9f\u73fe\u3059\u308b\u7701\u96fb\u529b\u753b\u50cf\u8a8d\u8b58", "\u9650\u3089\u308c\u305f\u30ea\u30bd\u30fc\u30b9\u3067\u306eAI\u6027\u80fd\u5411\u4e0a\u306e\u79d8\u8a23", "YOLO8\u3092\u4f7f\u3063\u305f\u4f4e\u89e3\u50cf\u5ea6\u753b\u50cf\u8a8d\u8b58\u306e\u53ef\u80fd\u6027", "\u81ea\u4f5cAI\u30e2\u30c7\u30eb\u3067\u30a8\u30c3\u30b8\u30c7\u30d0\u30a4\u30b9\u3092\u6d3b\u7528\u3059\u308b\u65b9\u6cd5"]}