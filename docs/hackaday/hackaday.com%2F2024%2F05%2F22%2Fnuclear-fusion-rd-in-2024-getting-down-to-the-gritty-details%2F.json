{"pubDate": "2024-05-22T17:00:39", "original_title": "Nuclear Fusion R&D In 2024: Getting Down To the Gritty Details", "link": "https://hackaday.com/2024/05/22/nuclear-fusion-rd-in-2024-getting-down-to-the-gritty-details/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2022/12/LaserFusion.jpg", "original_content": "To those who have kept tabs on nuclear fusion research the past decades beyond the articles and soundbites in news outlets, its probably clear just how much progress has been made, and how many challenges still remain. Yet since not that many people are into plasma physics, every measure of progress, such as most recently by the South Korean KSTAR (Korea Superconducting Tokamak Advanced Research) tokamak, is met generally by dismissive statements about nuclear fusion always being a certain number of decades away. Looking beyond this in coverage such as the article by Science Alert about this achievement by KSTAR we can however see quite a few of these remaining challenges being touched upon.\nRecently KSTAR managed to generate 100 million degrees C plasma and maintain this for 48 seconds, a significant boost over its previous record from 2021 of 30 seconds, partially due to the new divertors that were installed. These divertors are essential for removing impurities from the plasma, yet much like the inner wall of the reactor vessel, these plasma-facing materials (PFM) bear the brunt of the super-hot plasma and any plasma instabilities, as well as the constant neutron flux from the fusion products. KSTAR now features tungsten divertors, which has become a popular material choice for this component.\nResearching the optimal PFMs, as well as plasma containment modes and methods to suppress plasma instabilities are just some of the challenges that form the road still ahead before commercial fusion can commence.\n\nHigh-Confinement Mode\nThe KSTAR fusion reactor.\nThe high-confinement (or H-mode) operating regime of tokamaks was first discovered in 1982 during experiments with the German ASDEX tokamak. H-mode differs from the retroactively named L-mode (for low-confinement) in that it features a much more stable plasma edge, due to as of yet unknown mechanisms that take effect when the plasma is heated to above a certain level.\nOne issue with H-mode is however the occasional edge magnetohydrodynamic (MHD) instabilities, called edge-localized modes (ELM). These occur as disruptions in the otherwise stable edge barrier in H-mode, forming a sudden burst of plasma that can eject up to 20% of the plasmas energy into the nearby PFM. This causes damage to the wall and divertors in the form of erosion (ablation) and has been a major research topic for the past decades, with control methods like resonant magnetic perturbations (RMP) being applied as early as 2003. In 2011 KSTAR became one of the tokamaks that had managed to successfully suppress (Type I) ELMs using non-axisymmetric magnetic perturbations.\u00a0\nBeyond causing PFM damage, these instabilities in H-mode are also problematic in that they reduce the efficiency of the reactor, due to heat and other losses that then have to be compensated for. Yet the corollary of such a stable edge in H-mode with Type I ELM suppression is that the removal of impurities and heat from the plasma becomes very difficult. This is where the much smaller, Type II ELMs are relevant, as they provide a means to transport impurities across the edge barrier without threatening the PFM.\nThis was simulated and experimentally tested in the ASDEX Upgrade tokamak in 2022, with the results by G.F. Harrer et al. published in Physical Review Letters. Suggested is an operating regime for ITER and similar tokamak fusion reactors in which these Type II ELMs are used as a functional feature of the plasma, whereas Type I ELMs would continue to be suppressed. As for whether RMPs are the ideal way to suppress Type I ELMs, this too remains the subject of research.\nGreenwald Density\nBeyond H-mode and ELMs, tokamaks also have to deal with what is named the Greenwald Density Limit (GDL), named after Martin Greenwald, whose 2002 review article (PDF) in Plasma Physics and Controlled Fusion is worth a read for a detailed summary of the subject. The short version is that it pertains to the plasma density, with each fusion reactor having an observable lower and upper limit to this density. Once the limit is reached and exceeded in a tokamak, the reaction will transition from H- to L-mode, along with other negative effects . Of note is that the scaling of these limits seems to depend on a wide variety of factors, far beyond merely the size of the reactor, such as the fueling method.\nThe Greenwald limit is more easily found with stellarator fusion reactors, as these do not display the same strong negative response to exceeding this limit. Instead they show a soft limit, or quench, that sees the plasma temperature decaying. The density limit in stellarators has been found to be significantly higher (up to double) than in comparably sized tokamaks, giving the former an edge over tokamaks, as well as in terms of plasma stability. Despite this, it is thought that these limitations of tokamaks can be compensated for, with a 2024 article by S. Ding and colleagues in Nature detailing a high-density, high-confinement tokamak plasma regime in the General Atomics DIII-D tokamak.\nCant Rush Science\nIf you ask an engineer how long itll take to build something, they can likely give you a fairly accurate estimate, as well as an idea of the required materials and manpower. If you ask a plasma physics scientist how long itll take to build a nuclear fusion reactor that has an energy gain (Q) of 8 or better, theyll likely give you a quaint look. If youre lucky theyll humor you and introduce you to the wonderful world of nuclear fusion related research papers, especially those pertaining to ITER-related research.\nDuring the century since nuclear fusion was discovered, scientists have at some points thought that they were close to tackling nuclear fusion on Earth. The most pertinent being the Z-pinch machine during the 1950s, which was the moment when the solution seemed so close. This was also the moment when the exciting world of plasma physics began to be more fully revealed to the world of science, along with plasma instabilities, heat losses and a rush to find materials that could cope with the neutron flux and heat exposure inside the then brand new tokamak reactor design.\nWould larger tokamaks work better? This was just one question of many, even as fundamental research on plasma physics continued and the tokamaks at research institutes around the world underwent one revision after another based on newly gained knowledge and new directions in research. Along the edges stellarators continued to get some love too, especially once computer simulations became powerful enough to figure out an appropriate magnetic field configuration. Much like the plasma inside these experimental fusion reactors, so too did progress keep flowing.\nAlthough sideshows like inertial confinement fusion keep stealing the show despite being anything but practical for energy production, it is clear that we are lightyears beyond where we were with nuclear fusion research in the 1980s, as well as the 2000s. We cannot say yet when the moment will come when the first Q 8 fusion reactor will come online, with sustained tritium breeding and all of the other amenities that befit a commercial fusion reactor, but thats why we are still in the research and development phase.\nMaybe it will take another decade, or two. Maybe well have another sad Z-pinch moment where physics throws us another curveball and we have to sigh, collect our shattered self-esteem and waddle back to the drawing board for another shot at the challenge. This is both the thrill and curse of fundamental research and development, with often massive potential rewards, and absolutely zero guarantee of reaping any of them, other than learning so incredibly much along the way."}