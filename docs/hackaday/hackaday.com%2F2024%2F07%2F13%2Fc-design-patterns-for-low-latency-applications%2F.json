{"pubDate": "2024-07-14T02:00:53", "original_title": "C++ Design Patterns for Low-Latency Applications", "link": "https://hackaday.com/2024/07/13/c-design-patterns-for-low-latency-applications/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/07/speed_improvement_by_optimization_technique_bilokon_et_al_2023.jpg", "original_content": "With performance optimizations seemingly having lost their relevance in an era of ever-increasing hardware performance, there are still many good reasons to spend some time optimizing code. In a recent preprint article by [Paul Bilokon] and [Burak Gunduz] of the Imperial College London the focus is specifically on low-latency patterns that are relevant for applications such as high-frequency trading (HFT). In HFT the small margins are compensated for by churning through absolutely massive volumes of trades, all of which relies on extremely low latency to gain every advantage. Although FPGA-based solutions are very common in HFT due their low-latency, high-parallelism, C++ is the main language being used beyond FPGAs.\nAlthough many of the optimizations listed in the paper are quite obvious, such as prewarming the CPU caches, using constexpr, loop unrolling and use of inlining, other patterns are less obvious, such as hotpath versus coldpath. This overlaps with the branch reduction pattern, with both patterns involving the separation of commonly and rarely executed code (like error handling and logging), improving use of the CPUs caches and preventing branch mispredictions, as the benchmarks (using Google Benchmark) clearly demonstrates. All design patterns can also be found in the GitHub repository.\nOther interesting tidbits are the impact of signed and unsigned comparisons, mixing floating point datatypes and of course lock-free programming using a ring buffer design. Only missing from this list appears to be aligned vs unaligned memory accesses and zero-copy optimizations, but those should be easy additions to implement and test next to the other optimizations in this paper.", "title": "\u9ad8\u5468\u6ce2\u53d6\u5f15\u5411\u3051\u306e\u4f4e\u9045\u5ef6\u30d1\u30bf\u30fc\u30f3\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u6700\u9069\u5316\u624b\u6cd5", "body": "\u9ad8\u6027\u80fd\u5316\u306e\u512a\u5148\u5ea6\u306f\u4f4e\u4e0b\u3057\u3066\u3044\u308b\u304c\u3001\u30b3\u30fc\u30c9\u3092\u6700\u9069\u5316\u3059\u308b\u7406\u7531\u306f\u591a\u3044\u3002HFT\u5411\u3051\u306e\u4f4e\u9045\u5ef6\u30d1\u30bf\u30fc\u30f3\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u8ad6\u6587\u3002FPGA\u306f\u4f4e\u9045\u5ef6\u3067\u4e00\u822c\u7684\u3060\u304c\u3001C++\u3082\u5e83\u304f\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u3002CPU\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u4e8b\u524d\u6e29\u3081\u3001constexpr\u306e\u4f7f\u7528\u3001\u30eb\u30fc\u30d7\u30a2\u30f3\u30ed\u30fc\u30ea\u30f3\u30b0\u3001\u30a4\u30f3\u30e9\u30a4\u30f3\u51e6\u7406\u304c\u91cd\u8981\u3002", "titles": ["\u9ad8\u5468\u6ce2\u53d6\u5f15\u5411\u3051\u306e\u4f4e\u9045\u5ef6\u30d1\u30bf\u30fc\u30f3\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u6700\u9069\u5316\u624b\u6cd5", "\u9ad8\u983b\u5ea6\u53d6\u5f15\u306b\u304a\u3051\u308b\u4f4e\u9045\u5ef6\u306e\u91cd\u8981\u6027\u3068FPGA\u5229\u7528\u306e\u4e00\u822c\u7684\u306a\u5b9f\u8df5", "C++\u3092\u4e2d\u5fc3\u306b\u63a1\u7528\u3055\u308c\u308b\u6700\u9069\u5316\u624b\u6cd5\u3068\u30c7\u30b6\u30a4\u30f3\u30d1\u30bf\u30fc\u30f3", "CPU\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u4e8b\u524d\u6696\u6a5f\u3001constexpr\u5229\u7528\u3001\u30eb\u30fc\u30d7\u5c55\u958b\u7b49\u306e\u6700\u9069\u5316\u624b\u6cd5", "\u30ed\u30c3\u30af\u30d5\u30ea\u30fc\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u3068\u30ea\u30f3\u30b0\u30d0\u30c3\u30d5\u30a1\u8a2d\u8a08\u306e\u5f71\u97ff\u306b\u95a2\u3059\u308b\u8208\u5473\u6df1\u3044\u77e5\u898b"]}