{"pubDate": "2025-12-23T15:00:09", "original_title": "Surviving the RAM Apocalypse With Software Optimizations", "link": "https://hackaday.com/2025/12/23/surviving-the-ram-apocalypse-with-software-optimizations/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2017/08/memory.jpg", "original_content": "To the surprise of almost nobody, the unprecedented build-out of datacenters and the equipping of them with servers for so-called AI has led to a massive shortage of certain components. With random access memory (RAM) being so far the most heavily affected and with storage in the form of HDDs and SSDs not far behind, this has led many to ask the question of how we will survive the coming months, years, decades, or however-long the current AI bubble will last.\nOne thing is already certain, and that is that we will have to make our current computer systems last longer, and forego simply tossing in more sticks of RAM in favor of doing more with less. This is easy to imagine for those of us who remember running a full-blown Windows desktop system on a sub-GHz x86 system with less than a GB of RAM, but might require some adjustment for everyone else.\nIn short, what can us software developers do differently to make a hundred MB of RAM stretch further, and make a GB of storage space look positively spacious again?\n\nJust What Happened?\nAt the risk of coming across as an in my day rant, around the year 2000 I was using an AMD Duron 600 system with probably about 256 MB of SDRAM that succeeded my previous Intel Celeron 400 system with an amazing 64 MB of SDRAM. With Windows 2000 (arguably still the best version of Windows) on its own roomy 1 GB HDD partition there was still plenty of room on the rest of the HDD for applications, documents and some multimedia content like music and videos.\nOn these systems I could run a browser with many tabs open, alongside an office suite, an IDE, chat applications like IRC and ICQ, an email client, filesharing applications, and much more, without the system breaking a sweat. In the Duron 600 system I would eventually install a Matrox G550 AGP videocard to do some dual-monitor action, like watching videos or consulting documentation while browsing or programming at the same time.\nFast-forward a few decades and you cannot even install Windows on a 1 GB partition, and it requires more RAM than that. A quick check on the Windows 10 system that Im typing this on shows that currently the Windows folder is nearly 27 GB in size and just the Thunderbird email client is gobbling up over 150 MB of RAM by itself. Compare this to the minimum Windows 2000 system requirements of a Pentium 133 MHz, 32 MB of RAM and 1 GB of free HDD space.\nThis raises the question of what the reason is for this increase, when that email client in the early 2000s had effectively the same features in a much smaller package, and Windows 2000 is effectively the same as Windows 7, 10 and now 11, at its core when it comes to its feature set.\nThe same is true for fast and light options like Linux, which I had once running on a 486DX2-66 system, a system on which the average Linux distribution today wont even launch the installer, unless you go for a minimalistic distro like Alpine Linux, which requires a mere 128 MB of RAM. Where does all this demand for extra RAM and disk storage come from? Is it just all lazy waste and bloat that merely fills up the available space like a noxious gas?\nAsking The Right Questions\nThe Windows 10 desktop. (Source: Microsoft)\nStorage and RAM requirements for software are linked in the sense that much of an applications code and related resources are loaded into RAM at some point, but there is also the part of RAM that gets filled with data that the application generates while running. This gives us a lens to find out where the higher requirements come from.\nIn the case of Windows, the increase in minimum storage space requirements from 1 GB to 32 GB for Windows 10 can be explained by something that happened when Windows Vista rolled around along with changes to WinSxS, which is Windows implementation of side-by-side assembly.\nBy putting all core OS files in a single WinSxS folder and hard-linking them to various locations in the file system, all files are kept in a single location, with their own manifest and previous versions kept around for easy rollback. In Windows 2000, WinSxS was not yet used for the whole OS like this, mostly just to prevent DLL Hell file duplication issues, but Vista and onwards leaned much more heavily into this approach as they literally dumped every single OS file into this folder.\nWhile that by itself isnt such an issue, keeping copies of older file versions ensured that with each Windows Update cycle the WinSxS folder grew a little bit more. This was confirmed in a 2008 TechNet blog post, and though really old files are supposed to be culled now, it clearly has ensured that a modern Windows installation grows to far beyond that of pre-Vista OSes.\nThus we have some idea of why disk storage size requirements are increasing, leading us to the next thing, which is\u00a0 the noticeable increase in binary size. This can be put down for a large part on increased levels of abstractions, both in system programming languages, as well as scripting languages and frameworks.\nLosing Sight Of The Hardware\nOver the past decades we have seen a major shift away from programming languages and language features that work directly with the hardware to ones that increasingly abstract away the hardware. This shift was obvious in the 90s already, with for example Visual Basic continuing the legacy of BASIC with a similar mild level of abstraction before Java arrived on the scene with its own virtual hardware platform that insisted that hardware was just an illusion that software developers ought to not bother with.\nSubsequently we saw .NET, JavaScript, Python, and kin surge to the foreground, offering easier programming and more portable code, yet at the same time increasing complexity, abstraction levels, as well as file sizes and memory usage. Most importantly, these languages abandoned the concept of programming the underlying hardware with as few levels of indirection as possible. This is something which has even become part of languages like C and C++, with my own loathing for this complexity and abstraction in C++ being very palpable.\nIn the case of a language like Python, its known to be exceedingly slow due to its architecture, which results in the atrocious CPython runtime as well as better, but far more complex alternatives. This is a software architecture that effectively ignores the hardwares architecture, which thus results in bringing in a lot of unnecessary complexity. Languages such as JavaScript also make this mistake, with a heavy runtime that requires features such as type-checking and garbage collection that add complexity, while needing more code to enable features like Just-In-Time compilation to keep things still somewhat zippy.\nWith Java we even saw special JVM processor extensions being added to ARM processor with Jazelle direct bytecode execution (DBX) to make mobile games on cellphones programmed in J2ME not run at less than 1 FPS. Clearly if the software refuses to work with the hardware, the hardware has to adapt to the software.\nBy the time that youre a few levels of abstraction, various convenient frameworks and multiple layers of indirection down the proverbial rabbit hole, suddenly your applications codebase has ballooned by a few 100k LoC, the final binary comes in at 100+ MB and dial-up users just whimper as they see the size of the installer. But at least now we know why modern-day Thunderbird uses more RAM than what an average PC would have had installed around 1999.\nNot All Hope Is Lost\nTheres no need to return to the days of chiseling raw assembly into stone tables like in the days when the 6502\u00a0 and Z80 still reigned supreme. All we need to do to make the most of the RAM and storage we have, is to ask ourselves at each point whether there isnt a more direct and less complex way. What this looks like will depend on the application, but the approach that I like to use with my own projects is that of the chronically lazy developer who doesnt like writing more code than absolutely necessary, hates complexity because it takes effort and whose eyes glaze over at overly verbose documentation.\nOne could argue that theres considerable overlap between KISS and laziness, in the sense that a handful of source files accompanied by a brief Makefile is simultaneously less work and less complex than a MB+ codebase that exceeds the capabilities of a single developer with a basic editor like Notepad++ or Vim. This incidentally is why I do not use IDEs but prefer to only rely on outrageously advanced features such as syntax highlighting and auto-indent. Using my brain for human-powered Intellisense makes for a good mental exercise.\nI also avoid complex file formats like XML and their beefy parsers, preferring to instead use the INI format thats both much easier to edit and parse. For embedding scripting languages I use the strongly-typed AngelScript, which is effectively scriptable C++ and doesnt try any cute alternative architectures like Python or Lua do.\nRather than using bulky, overly bloated C++ frameworks like Boost, I use the much smaller and less complex Poco libraries, or my NPoco fork that targets FreeRTOS and similar embedded platforms. With my remote procedure call (RPC) framework NymphRPC I opted for a low-level, zero copy approach that tries to stick as closely to the CPU and memory systems capabilities as feasible to do the work with the fewest resources possible.\nWhile Im not trying to claim that my approach is the One True Approach, for me half the fun of programming is to do the required task in a very efficient and low-resource manner, which is why I ported for example FFmpeg to the ESP32 so that I could run the same project code on this MCU, rather than deal with the complexity and documentation Hell of Espressifs ESP-ADF framework.\nSure, I could probably have done something with MicroPython or so, but at the cost of a lot more storage and with far less performance.\u00a0Which gets us back again to why modern day PCs need so much RAM and storage. Its not a bug, but a feature of the system many of us opted for, or were told was the Modern Way.", "title": "- \u73fe\u4ee3\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306e\u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\uff1aRAM\u3068\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u8ab2\u984c", "body": "AI\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u306e\u6025\u5897\u306b\u3088\u308a\u3001RAM\u3084\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u4e0d\u8db3\u304c\u9855\u5728\u5316\u3002\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u958b\u767a\u8005\u306f\u30ea\u30bd\u30fc\u30b9\u52b9\u7387\u3092\u8003\u616e\u3057\u3066\u958b\u767a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002", "titles": ["- \u73fe\u4ee3\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306e\u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\uff1aRAM\u3068\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u8ab2\u984c", "- \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u958b\u767a\u8005\u304c\u5b66\u3076\u3079\u304d\u52b9\u7387\u7684\u306a\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u6cd5", "- \u5897\u3048\u7d9a\u3051\u308bOS\u306e\u8981\u6c42\uff1a\u904e\u53bb\u3068\u73fe\u5728\u306e\u6bd4\u8f03", "- \u62bd\u8c61\u5316\u306e\u5f71\u97ff\uff1a\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u304c\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306b\u4e0e\u3048\u308b\u5f71\u97ff", "- \u52b9\u7387\u7684\u306a\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\uff1a\u5c11\u306a\u3044\u30ea\u30bd\u30fc\u30b9\u3067\u6700\u5927\u306e\u52b9\u679c\u3092\u5f97\u308b\u65b9\u6cd5"]}