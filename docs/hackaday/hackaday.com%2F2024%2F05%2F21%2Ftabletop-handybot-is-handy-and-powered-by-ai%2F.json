{"pubDate": "2024-05-21T18:30:00", "original_title": "Tabletop Handybot is Handy, And Powered By AI", "link": "https://hackaday.com/2024/05/21/tabletop-handybot-is-handy-and-powered-by-ai/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/05/architecture_diagram_c06544.png", "original_content": "Decently useful AI has been around for a little while now, and robotic arms have been around much longer. Yet somehow, we dont have little robot helpers on our desks yet! Thankfully, [Yifei] is working towards that reality with Tabletop Handybot.\nWhat [Yifei] has developed is a robotic arm that accepts voice commands. The robot relies on a Realsense D435 RGB-D camera, which provides color vision with depth information as well. Grounding DINO is used for object detection on the RGB images. Segment Anything and Open3D are used for further processing of the visual and depth data to help the robot understand what its looking at. Meanwhile, voice commands are interpreted via OpenAI Whisper, which can feed prompts to ChatGPT for further processing.\n[Yifei] demonstrates his robot picking up markers on command, which is a pretty cool demo. With so many modern AI tools available, were getting closer to the ideal of robots that can understand and execute on general spoken instructions. This is a great example.\u00a0We may not be all the way there yet, but perhaps soon. Video after the break.\n\n"}