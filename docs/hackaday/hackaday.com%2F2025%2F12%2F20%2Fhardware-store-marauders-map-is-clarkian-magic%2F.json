{"pubDate": "2025-12-21T00:00:14", "original_title": "Hardware Store Marauder\u2019s Map is Clarkian Magic", "link": "https://hackaday.com/2025/12/20/hardware-store-marauders-map-is-clarkian-magic/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2025/12/dave-marauder-map.jpg", "youtube": "https://www.youtube.com/watch?v=dO32ImnsX", "original_content": "The Marauders Map is a magical artifact from the Harry Potter franchise. That sort of magic isnt real, but as Arthur C. Clarke famously pointed out, it doesnt need to be  we have technology, and we can make our own magic now. Or, rather, [Dave] on the YouTube Channel Daves Armoury can make it.\n[Dave]s hardware store might be in a rough neighborhood, since it has 50 cameras worth of CCTV coverage. In this case, the stockmans loss is the hackers gain, as [Dave] has talked his way into accessing all of those various camera feeds and is using machine vision to track every single human in the store.\nOf course, locating individuals in a video feed is easy  to locate them in space from that feed, one first needs an accurate map. To do that, [Dave] first 3D scans the entire store with a rover. The scan is in full 3D, and its no small amount of data. On the rover, a Jetson AGX is required to handle it; on the bench, a beefy HP Z8 Fury workstation crunches the point cloud into a map. Luckily it came with 500 GB of RAM, since just opening the mesh file generated from that point cloud needs 126 GB. That is processed into a simple 2D floor plan. While the workflow is impressive, we cant help but wonder if there was an easier way. (Maybe a tape measure?)\nOnce an accurate map has been generated, it turns out NVIDIA already has a turnkey solution for mapping video feeds to a 2D spatial map. When processing so much data  remember, there are 50 camera feeds in the store  its not ideal to be passing the image data from RAM to GPU and back again, but luckily NVIDIAs Deep Stream pipeline will do object detection and tracking (including between different video streams) all on the GPU. Theres also pose estimation right in there for more accurate tracking of where a person is standing than just inside this red box. With 50 cameras, its all a bit much for one card, but luckily [Dave]s workstation has two GPUs.\nOnce the coordinates are spat out of the neural networks, its relatively simple to put footprints on the map in true Harry Potter fashion. It really is magic, in the Clarkian sense, what you can do if you throw enough computing power at it.\nUnfortunately for show-accuracy (or fortunately, if you prefer to avoid gross privacy violations), it doesnt track every individual by name, but it does demonstrate the possibility with [Dave] and his robot. If you want a map of something else maybe check out this backyard project.\n\n"}