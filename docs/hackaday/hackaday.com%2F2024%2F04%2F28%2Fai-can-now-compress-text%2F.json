{"pubDate": "2024-04-29T05:00:22", "original_title": "AI Can Now Compress Text", "link": "https://hackaday.com/2024/04/28/ai-can-now-compress-text/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/04/text-compression-featured.jpg", "original_content": "There are many claims in the air about the capabilities of AI systems, as the technology continues to ascend the dizzy heights of the hype cycle. Some of them are true, others stretch definitions a little, while yet more cross the line into the definitely bogus. [J] has one that is backed up by real code though, a compression scheme for text using an AI, and while there may be limitations in its approach, it demonstrates an interesting feature of large language models.\nThe compression works by assuming that for a sufficiently large model, its likely that many source texts will exist somewhere in the training. Using llama.cpp its possible to extract the tokenization information of a piece of text contained in its training data and store that as the compressed output. The decompressor can then use that tokenization data as a series of keys to reassemble the original from its training. Were not AI experts but we are guessing that a source text which has little in common with any training text would fare badly, and we expect that the same model would have to be used on both compression and decompression. It remains a worthy technique though, and no doubt because it has AI pixie dust, somewhere theres a hype-blinded venture capitalist who would pay millions for it. What a world we live in!\nOddly this isnt the first time weve looked at AI text compression."}