{"pubDate": "2024-11-20T12:00:32", "original_title": "An Animated Walkthrough of How Large Language Models Work", "link": "https://hackaday.com/2024/11/20/an-animated-walkthrough-of-how-large-language-models-work/", "source": "https://hackaday.com/blog/feed/", "thumbnail": "https://hackaday.com/wp-content/uploads/2024/11/LLM-Anim-visualization.gif", "original_content": "If you wonder how Large Language Models (LLMs) work and arent afraid of getting a bit technical, dont miss [Brendan Bycroft]s LLM Visualization. It is an interactively-animated step-by-step walk-through of a GPT large language model complete with animated and interactive 3D block diagram of everything going on under the hood. Check it out!\nnano-gpt has only around 85,000 parameters, but the operating principles are all the same as for larger models.\nThe demonstration walks through a simple task and shows every step. The task is this: using the nano-gpt model, take a sequence of six letters and put them into alphabetical order.\nA GPT model is a highly complex prediction engine, so the whole process begins with tokenizing the input (breaking up words and assigning numerical values to the chunks) and ends with choosing an appropriate output from a list of probabilities. There are of course many more steps in between, and different ways to adjust the models behavior. All of these are made quite clear by [Brendan]s process breakdown.\nWeve previously covered how LLMs work, explained without math which eschews gritty technical details in favor of focusing on functionality, but its also nice to see an approach like this one, which embraces the technical elements of exactly what is going on.\nWeve also seen a much higher-level peek at how a modern AI model like Anthropics Claude works when it processes requests, extracting human-understandable concepts that illustrate whats going on under the hood."}